{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e586c0-7eac-4959-a34c-4862e016bb0e",
   "metadata": {},
   "source": [
    "# Hubbard12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9e843-eee5-44df-9732-0b005cc9aa50",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865ba75-53f6-44cf-b597-58fefa13f2de",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d67ea4c-5af9-4d04-9ac5-b083a562d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifim.bench\n",
    "import classifim.bench.fidelity\n",
    "import classifim.bench.metric\n",
    "import classifim.bench.plot_tools\n",
    "import classifim.utils\n",
    "import classifim_gen.fil24_hamiltonian\n",
    "import classifim_gen.gs_cache\n",
    "import classifim_gen.gs_utils\n",
    "import classifim_gen.hubbard_hamiltonian\n",
    "import classifim_gen.io\n",
    "import concurrent.futures\n",
    "import functools\n",
    "import importlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import scipy.sparse.linalg\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e21e3-890a-490f-b63b-86497f723773",
   "metadata": {},
   "source": [
    "The following settings were used to generate the images for the main paper. They are commented out (the cell is made \"raw\" using CTRL+R, use CTRL+Y to make it \"code\") since they require a LaTeX installation with some fonts and packages used by matplotlib."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb890aa8-973f-41b3-b492-5a1a64ba58eb",
   "metadata": {},
   "source": [
    "# [Optional]: matplotlib.backend_bases.register_backend('pgf', FigureCanvasPgf)\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc2e741-8222-4ea0-b6d4-bf27831d53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_NAME = \"Hubbard12\"\n",
    "DATA_DIR0 = classifim.utils.find_data_dir()\n",
    "assert os.path.isdir(DATA_DIR0)\n",
    "DATA_DIR = classifim.utils.maybe_create_subdir(DATA_DIR0, SM_NAME.lower())\n",
    "\n",
    "HF_DATA_DIR0 = classifim.utils.find_data_dir(\"hf_data_dir\")\n",
    "HF_DATA_DIR = classifim.utils.maybe_create_subdir(HF_DATA_DIR0, \"hubbard_12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86da147a-fc13-4c0e-9ec8-6e3cc6078731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_family = classifim_gen.hubbard_hamiltonian.Hubbard1DFamily(dtype_float=np.float64, xp=np)\n",
    "param_conversions = classifim_gen.hubbard_hamiltonian.HubbardParamsConversions(ham_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a7b521-a1bc-4aef-8e4f-55cdcdd09b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def get_lanczos_cache():\n",
    "    \"\"\"\n",
    "    Returns lanczos_cache without a way to compute new values.\n",
    "    \"\"\"\n",
    "    DATA_LANCZOS_DIR = os.path.join(DATA_DIR, \"lanczos\")\n",
    "    assert os.path.exists(DATA_LANCZOS_DIR)\n",
    "    return classifim_gen.gs_cache.GroundStateCache(\n",
    "        compute_ground_state=None,\n",
    "        param_keys=ham_family.PARAM_NAMES,\n",
    "        ham_name=SM_NAME.lower(),\n",
    "        save_path=DATA_LANCZOS_DIR,\n",
    "        load_meta=True,\n",
    "        filename_source=classifim_gen.gs_cache.FS_FILESYSTEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554a1df-8c8f-44c6-a067-536dd2f0ebb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### About Hubbard12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b47a8-fb28-430b-88c8-16a351051200",
   "metadata": {},
   "source": [
    "**Hubbard Hamiltonian**\n",
    "\n",
    "Consider a lattice $\\Lambda = \\mathbb{Z}^2 / a_{\\Lambda} \\mathbb{Z}^2$ where\n",
    "$a_{\\Lambda}$ is an invertible $2\\times 2$ matrix with integer coefficients.\n",
    "The number of sites is $\\left|\\Lambda\\right| = \\left|\\det(a_{\\Lambda})\\right|$.\n",
    "Each site $j \\in \\Lambda$ has neighbors\n",
    "$$\\text{NN}(j) = \\left\\{j + v: v \\in \\left\\{\n",
    "\\left(\\begin{smallmatrix}-1\\\\0\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}0\\\\-1\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}0\\\\1\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}1\\\\0\\end{smallmatrix}\\right)\n",
    "\\right\\}\\right\\}$$\n",
    "and diagonal neighbours\n",
    "$$\\text{NNN}(j) = \\left\\{j + v: v \\in \\left\\{\n",
    "\\left(\\begin{smallmatrix}-1\\\\-1\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}-1\\\\1\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}1\\\\-1\\end{smallmatrix}\\right),\n",
    "\\left(\\begin{smallmatrix}1\\\\1\\end{smallmatrix}\\right)\n",
    "\\right\\}\\right\\}.$$\n",
    "We introduce $\\text{NN}(\\Lambda)=\\{(i,j): i\\in \\text{NN}(j)\\}$, $\\text{NNN}(\\Lambda)=\\{(i,j): i\\in \\text{NNN}(j)\\}$\n",
    "for respectively regular and diagonal edges of the lattice $\\Lambda$.\n",
    "\n",
    "Each site $j$ of the lattice $\\Lambda$ has 2 slots for an electron enumerated by spin $\\sigma\\in\\{\\uparrow,\\downarrow\\}$\n",
    "with creation and annihilation operators $c_{j\\sigma}^\\dagger$ and $c_{j\\sigma}$. We consider the Hubbard Hamiltonian family given by\n",
    "$$H = u H_{\\text{int}} + t H_{\\text{NN}} + t' H_{\\text{NNN}},$$\n",
    "where\n",
    "$$\n",
    "H_{\\text{int}} = \\sum_{i\\in\\Lambda} (n_{j\\uparrow}-1/2) (n_{j\\downarrow}-1/2),\n",
    "\\qquad n_{j\\sigma} = c_{j\\sigma}^{\\dagger} c_{j\\sigma},\n",
    "$$\n",
    "$$\n",
    "H_{\\text{NN}} = -\\sum_{(i,j)\\in\\text{NN}(\\Lambda),\\sigma}c_{i\\sigma}^{\\dagger}c_{j\\sigma},\n",
    "\\qquad H_{\\text{NNN}} = -\\sum_{(i,j)\\in\\text{NNN}(\\Lambda),\\sigma}c_{i\\sigma}^{\\dagger}c_{j\\sigma}.\n",
    "$$\n",
    "\n",
    "Since $N_{\\uparrow} = \\sum_{j} n_{j\\uparrow}$ and $N_{\\downarrow} = \\sum_{j} n_{j\\downarrow}$\n",
    "are symmetries of the Hamiltonian, we can restrict our attention to a sector with fixed\n",
    "values of both. We pick $N_{\\uparrow} = N_{\\downarrow} = \\left|\\Lambda\\right|/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966885a7-c46a-4818-9d8a-4cc4520672f4",
   "metadata": {},
   "source": [
    "**Lattice choice**\n",
    "\n",
    "We pick $\\left|\\det(a_{\\Lambda})\\right|=12$ since there are $924^2 = 853776$ configurations with $N_{\\uparrow} = N_{\\downarrow} = \\left|\\Lambda\\right|/2$ at this lattice size (larger sizes will be too slow). There are the following keeping the NN graph bipartite:\n",
    "\n",
    "* 10: $\\left(\\begin{smallmatrix}5&1\\\\5&-1\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}1&2\\\\5&0\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}1&3\\\\3&-1\\end{smallmatrix}\\right)$,\n",
    "* 12: $\\left(\\begin{smallmatrix}6&1\\\\6&-1\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}3&2\\\\3&-2\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}4&2\\\\2&-2\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}1&4\\\\3&0\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}0&6\\\\2&0\\end{smallmatrix}\\right)$,\n",
    "* 14: $\\left(\\begin{smallmatrix}7&1\\\\7&-1\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}1&2\\\\7&0\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}2&3\\\\4&-1\\end{smallmatrix}\\right)$,\n",
    "* 16: $\\left(\\begin{smallmatrix}8&1\\\\8&-1\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}4&2\\\\4&-2\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}5&2\\\\3&-2\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}1&5\\\\3&-1\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}0&4\\\\4&0\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}0&8\\\\2&0\\end{smallmatrix}\\right),\\left(\\begin{smallmatrix}2&4\\\\4&0\\end{smallmatrix}\\right)$.\n",
    "\n",
    "\n",
    "\n",
    "We pick $a_{\\Lambda} = \\left(\\begin{smallmatrix}0&-3\\\\4&1\\end{smallmatrix}\\right)$, $\\det(a_{\\Lambda}) = 12$.\n",
    "We number the vertices of the lattice $\\Lambda$ by integers $0,\\dots,11$, where integer $j$ corresponds to\n",
    "$\\left[\\left(\\begin{smallmatrix}j\\\\0\\end{smallmatrix}\\right)\\right]\\in \\Lambda$.\n",
    "\n",
    "We have\n",
    "$$\\text{NN}(j) = \\{(j\\pm 1)\\%12,(j\\pm 3)\\%12\\},\\qquad \\text{NNN}(j) = \\{(j\\pm 2)\\%12, (j\\pm 4)\\%12\\}.$$\n",
    "\n",
    "For implementation, we represent $\\uparrow$ with $0$, $\\downarrow$ with $1$, and order the creation operators as follows:\n",
    "$$\n",
    "  c_{(\\left|\\Lambda\\right|-1)\\downarrow}^\\dagger \\cdots c_{0\\downarrow}^\\dagger\n",
    "  c_{(\\left|\\Lambda\\right|-1)  \\uparrow}^\\dagger \\cdots c_{0  \\uparrow}^\\dagger\n",
    "  \\left|0\\right>\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35eab0b8-8934-4d2e-8ac0-749e88d7a2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible bitstrings in Hubbard12 is 924**2 = 853776.\n"
     ]
    }
   ],
   "source": [
    "n_configs_per_spin = scipy.special.comb(ham_family.nsites, ham_family.nsites // 2, exact=True)\n",
    "print(f\"Number of possible bitstrings in Hubbard{ham_family.nsites} is {n_configs_per_spin}**2 = {n_configs_per_spin**2}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e795811-91f3-490b-8c40-d5e578214625",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392ded9-9a3f-4194-aa00-8e4e0f8834db",
   "metadata": {},
   "source": [
    "### Lanczos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc815f8e-568d-4eff-b6a5-b4065817fc8b",
   "metadata": {},
   "source": [
    "* Requires: nothing\n",
    "* Generates: ground state vectors and probabilities in lanczos dir (but takes weeks to do so, use HPC instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f457b8-eba9-4fbc-8981-a132f173f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lanczos_f(ncv, maxiter):\n",
    "    def compute_lanczos(params_vec):\n",
    "        return classifim_gen.gs_utils.compute_lanczos(\n",
    "            params_vec,\n",
    "            ham_family=ham_family,\n",
    "            k=4,\n",
    "            ncv=ncv,\n",
    "            maxiter=maxiter,\n",
    "            beta=1.0e7,\n",
    "            payload=None,\n",
    "            verbose=False\n",
    "        )\n",
    "    return compute_lanczos\n",
    "resolution = 64\n",
    "lambdas = np.array([(lambdai0 / resolution, lambdai1 / resolution) for lambdai0 in range(resolution) for lambdai1 in range(resolution)])\n",
    "param_vecs = np.array(param_conversions.lambdas_to_params(*lambdas.T)).T\n",
    "DATA_LANCZOS_DIR = classifim.utils.maybe_create_subdir(DATA_DIR, \"lanczos\")\n",
    "lanczos_cache = classifim.bench.GroundStateCache(\n",
    "    # ncv and maxiter need to be increased for some points.\n",
    "    compute_ground_state=compute_lanczos_f(40, 40),\n",
    "    param_keys=ham_family.PARAM_NAMES,\n",
    "    ham_name=SM_NAME.lower(),\n",
    "    save_path=DATA_LANCZOS_DIR,\n",
    "    load_meta=True,\n",
    "    filename_source=classifim_gen.gs_cache.FS_FILESYSTEM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8237c-ff70-4b3f-9ba3-e2d60566ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should compute \"ground state\" for all values of parameters in theory.\n",
    "# Takes weeks in practice.\n",
    "LOCK_FILE_PATH = os.path.join(DATA_LANCZOS_DIR, f\"{SM_NAME.lower()}_bench.lock\")\n",
    "num_success = 0\n",
    "num_error = 0\n",
    "num_skipped = 0\n",
    "done = False\n",
    "with classifim_gen.gs_utils.ProcessLockFile(LOCK_FILE_PATH) as process_lock:\n",
    "    print(f\"Locked using '{LOCK_FILE_PATH}'. Remove to stop softly.\")\n",
    "    try:\n",
    "        for ncv in (40, 60, 90, 130, 200):\n",
    "            if done or num_success + num_skipped >= param_vecs.shape[0]:\n",
    "                break\n",
    "            num_success = 0\n",
    "            num_error = 0\n",
    "            num_skipped = 0\n",
    "            # Use maxiter = ncv. This can be optimized further.\n",
    "            lanczos_cache.compute_ground_state = compute_lanczos_f(ncv, maxiter=ncv)\n",
    "            progress_printer = classifim.bench.ProgressPrinter()\n",
    "            progress_printer.pprintln(f\"Start time: {progress_printer.get_now_str()}\")\n",
    "            for param_vec in param_vecs:\n",
    "                if not process_lock.exists():\n",
    "                    progress_printer.pprintln(f\"\\rLock file '{LOCK_FILE_PATH}' removed; exiting.\")\n",
    "                    done = True\n",
    "                    break\n",
    "                try:\n",
    "                    res = lanczos_cache.get_ground_state(tuple(param_vec), load=False)\n",
    "                except classifim_gen.gs_cache.GroundStateComputationError:\n",
    "                    res = 'error'\n",
    "                if res is None:\n",
    "                    num_skipped += 1\n",
    "                    progress_printer.inc_i(char='.')\n",
    "                elif res == 'error':\n",
    "                    num_error += 1\n",
    "                    progress_printer.inc_i(char='E')\n",
    "                else:\n",
    "                    num_success += 1\n",
    "                    progress_printer.inc_i(char='S')\n",
    "            progress_printer.pprintln(f\"\\r{ncv=} done: {num_success=} {num_error=} {num_skipped=}\")\n",
    "    finally:\n",
    "        lanczos_cache.save_meta()\n",
    "        progress_printer.pprintln(f\"\\rEnd time: {progress_printer.get_now_str()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883c21a-2053-4ecb-89f5-bff4cb26255a",
   "metadata": {},
   "source": [
    "### Generate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8676b0-dc5e-40c0-ac26-fa4622a4fa2c",
   "metadata": {},
   "source": [
    "* Requires: ground state probabilities in \"lanczos\" directory.\n",
    "* Generates: classifim_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1e43b-c8dd-4490-8283-304c5c913d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "BITCHIFC_DATASET_DIR = classifim.utils.maybe_create_subdir(DATA_DIR, \"classifim_datasets\")\n",
    "lanczos_cache = get_lanczos_cache()\n",
    "resolution = 64\n",
    "lambdas = np.array([\n",
    "    (lambda0, lambda1)\n",
    "    for lambda0 in np.arange(resolution) / resolution\n",
    "    for lambda1 in np.arange(resolution) / resolution])\n",
    "params_vecs = np.array(param_conversions.lambdas_to_params(*lambdas.T)).T\n",
    "print(f\"{params_vecs.shape=}\")\n",
    "datasets = classifim_gen.gs_utils.generate_datasets(\n",
    "    gs_cache=lanczos_cache,\n",
    "    lambdas=lambdas,\n",
    "    params_vecs=params_vecs,\n",
    "    vi_to_z=ham_family.vi_to_z,\n",
    "    seeds=range(42, 52))\n",
    "\n",
    "for dataset in datasets:\n",
    "    seed = dataset[\"seed\"]\n",
    "    dataset_file_name =  os.path.join(BITCHIFC_DATASET_DIR, f\"dataset_{seed}.npz\")\n",
    "    np.savez_compressed(dataset_file_name, **dataset)\n",
    "    print(f\"Dataset is saved to '{dataset_file_name}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d641bc5-6f83-4132-96d4-177f6821d817",
   "metadata": {},
   "source": [
    "### Compute ground truth FIM\n",
    "\n",
    "* Requires: ground state probabilities in \"lanczos\" directory.\n",
    "* Generates: ground truth FIM (`fim/gs_fim.npz`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67265106-479b-40dd-b1da-58b234629f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FIM_DIR = classifim.utils.maybe_create_subdir(DATA_DIR, \"fim\")\n",
    "lanczos_cache = get_lanczos_cache()\n",
    "\n",
    "gs_fim = classifim.bench.fidelity.compute_2d_fim(\n",
    "    param_conversions.lambdas_to_params, lanczos_cache,\n",
    "    resolution=64, verbose=True)\n",
    "\n",
    "gs_fim_npz = {}\n",
    "for key, value in gs_fim.items():\n",
    "    np_value = value.to_numpy()\n",
    "    if np_value.dtype == object:\n",
    "        np_value = np_value.astype(bytes)\n",
    "    gs_fim_npz[key] = np_value\n",
    "\n",
    "gs_fim_filename = os.path.join(FIM_DIR, \"gs_fim.npz\")\n",
    "np.savez_compressed(\n",
    "    gs_fim_filename,\n",
    "    **gs_fim_npz)\n",
    "print(f\"gs_fim saved to '{gs_fim_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42323b24-8253-48e6-87d5-07ad3bba2763",
   "metadata": {},
   "source": [
    "### Convert to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cff9d502-98d6-464d-a5e5-92e9788ce511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(classifim_gen.io)\n",
    "importlib.reload(classifim_gen.hubbard_hamiltonian)\n",
    "data_seeds = classifim_gen.io.save_datasets_for_hf(\n",
    "    convert_f=classifim_gen.hubbard_hamiltonian.convert_dataset_to_hf,\n",
    "    input_pattern=os.path.join(DATA_DIR, \"classifim_datasets\", \"dataset_{seed}.npz\"),\n",
    "    output_dir=HF_DATA_DIR,\n",
    "    overwrite=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "700c7c40-e01c-4b24-868f-60891cb3fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(DATA_DIR, \"fim\", \"gs_fim.npz\")) as f:\n",
    "    fim_npz = dict(f)\n",
    "gt_fim_filename = os.path.join(HF_DATA_DIR, \"gt_fim.parquet\")\n",
    "pq.write_table(pa.Table.from_pydict(fim_npz), gt_fim_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50fe04ea-bb0e-4f55-8c18-4fa5eb5e1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- config_name: hubbard_12.gt_fim\n",
      "  data_files:\n",
      "  - split: test\n",
      "    path: hubbard_12/gt_fim.parquet\n",
      "- config_name: hubbard_12.seed42\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_42/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_42/d_test.parquet\n",
      "- config_name: hubbard_12.seed43\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_43/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_43/d_test.parquet\n",
      "- config_name: hubbard_12.seed44\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_44/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_44/d_test.parquet\n",
      "- config_name: hubbard_12.seed45\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_45/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_45/d_test.parquet\n",
      "- config_name: hubbard_12.seed46\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_46/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_46/d_test.parquet\n",
      "- config_name: hubbard_12.seed47\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_47/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_47/d_test.parquet\n",
      "- config_name: hubbard_12.seed48\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_48/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_48/d_test.parquet\n",
      "- config_name: hubbard_12.seed49\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_49/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_49/d_test.parquet\n",
      "- config_name: hubbard_12.seed50\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_50/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_50/d_test.parquet\n",
      "- config_name: hubbard_12.seed51\n",
      "  data_files:\n",
      "  - split: train\n",
      "    path: hubbard_12/seed_51/d_train.parquet\n",
      "  - split: test\n",
      "    path: hubbard_12/seed_51/d_test.parquet\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(classifim_gen.io)\n",
    "print(classifim_gen.io.gen_config_yml(\n",
    "    sm_name=os.path.basename(HF_DATA_DIR),\n",
    "    seeds=sorted(data_seeds),\n",
    "    fim_seeds=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19bab3-1250-4970-9c5c-84ba8b3bdd3a",
   "metadata": {},
   "source": [
    "## Best possible cross entropy error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f01c3-2eab-4fed-b45b-4636c9c8bc3b",
   "metadata": {},
   "source": [
    "* Requires:\n",
    "    - Ground state probabilities in 'lanczos' dir\n",
    "    - Test dumps (produced by `twelve_sites_classifim.ipynb`) at `classifim_datasets/test_dump_{seed}.npz`.\n",
    "* Prints out best possible cross entropy error (for an algorithm which knows ground state probabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bb8fa-c506-4ead-9cd7-ed56ac10fe2f",
   "metadata": {},
   "source": [
    "#### Compute and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8419ad9e-276b-47c5-a6de-280492fb6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [12:38<00:00,  5.40it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [01:59<00:00, 34.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [02:00<00:00, 34.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [01:59<00:00, 34.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [02:00<00:00, 33.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [02:00<00:00, 34.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [01:59<00:00, 34.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [02:00<00:00, 34.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [01:59<00:00, 34.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [01:59<00:00, 34.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "DATASETS_DIR = os.path.join(DATA_DIR, \"classifim_datasets\")\n",
    "assert os.path.isdir(DATASETS_DIR)\n",
    "\n",
    "def zs_to_vi_f(zs):\n",
    "    z_up = zs & ((1 << 12) - 1)\n",
    "    z_down = zs >> 12\n",
    "    vi = ham_family.z_to_vi(z_down, z_up)\n",
    "    return vi\n",
    "\n",
    "best_xes = {}\n",
    "for seed in range(42, 52):\n",
    "    res = classifim.bench.fil24_hamiltonian.compute_best_possible_xe(\n",
    "        dump_npz=np.load(os.path.join(DATASETS_DIR, f\"test_dump_{seed}.npz\")),\n",
    "        zs_to_vi_f=zs_to_vi_f,\n",
    "        lambdas_to_params_f=param_conversions.lambdas_to_params,\n",
    "        probs_cache=get_lanczos_cache(),\n",
    "        resolution=64)\n",
    "    best_xes[seed] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c1c964-cbb1-4d29-bfaf-59522678dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS_DIR = os.path.join(DATA_DIR, \"metrics\")\n",
    "best_xes_filename = os.path.join(METRICS_DIR, \"best_xes.npz\")\n",
    "np.savez_compressed(\n",
    "    best_xes_filename,\n",
    "    seeds=np.array(list(best_xes.keys())),\n",
    "    best_xes=np.array(list(best_xes.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b80bf-71e7-4ba1-ac73-894c5bb0bc15",
   "metadata": {},
   "source": [
    "#### Load and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8508a1-021d-48bb-bfd5-31a63caaf63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best possible XE: 0.2380 \\pm 0.0009\n"
     ]
    }
   ],
   "source": [
    "METRICS_DIR = os.path.join(DATA_DIR, \"metrics\")\n",
    "best_xes_filename = os.path.join(METRICS_DIR, \"best_xes.npz\")\n",
    "with np.load(best_xes_filename) as f:\n",
    "    best_xes = dict(f)\n",
    "summary = classifim.bench.metric.normal_summary(best_xes[\"best_xes\"])\n",
    "print(f\"Best possible XE: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe260af-91c6-483a-83ad-8ecac6153c62",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1999c63-02d1-471c-93d0-e8e7c368fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(DATA_DIR, \"classifim_datasets/dataset_42.npz\")) as f:\n",
    "    npz_ds = dict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a952ad30-b1c2-48cf-a7d4-e29abb7028cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambdas': array([[0.      , 0.      ],\n",
       "        [0.      , 0.      ],\n",
       "        [0.      , 0.      ],\n",
       "        ...,\n",
       "        [0.984375, 0.984375],\n",
       "        [0.984375, 0.984375],\n",
       "        [0.984375, 0.984375]]),\n",
       " 'zs': array([13845195,  5737095,  8030295, ..., 10647372, 11626380,   653989],\n",
       "       dtype=uint32),\n",
       " 'seed': array(42)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c0a1c6-18e0-47c8-b168-0b1621934bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambdas: float64 (573440, 2)\n",
      "zs: uint32 (573440,)\n",
      "seed: int64 42\n"
     ]
    }
   ],
   "source": [
    "for k, v in npz_ds.items():\n",
    "    v_info = v.item() if v.size == 1 else v.shape\n",
    "    print(f\"{k}: {v.dtype} {v_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c52846-ca08-4148-a7b2-e544f098c548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:classifim]",
   "language": "python",
   "name": "conda-env-classifim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
